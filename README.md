# ğŸ¤– AnswerGPT

AnswerGPT is a real-time, context-aware, hybrid chatbot powered by:

- ğŸ§  **Phi-2** â€” A powerful, lightweight language model by Microsoft
- ğŸ“¦ **QLoRA Fine-Tuning** â€” Trained on your own interactions
- ğŸ’¾ **Qdrant Vector DB** â€” For memory storage and semantic search
- ğŸŒ **DuckDuckGo Web Scraping** â€” To pull live, real-world info
- ğŸ›ï¸ **Gradio Web UI** â€” For a slick ChatGPT-style interface

---

## ğŸš€ Features

âœ… Fine-tuned local model (Phi-2 + QLoRA)
âœ… Real-time web + memory hybrid answering
âœ… Custom prompt formatting
âœ… Add long-term memory via `remember` command
âœ… Local Gradio UI
âœ… Modular and hackable Python code

---

## ğŸ§± Project Structure

```
answergpt/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                  # CLI chatbot
â”‚   â”œâ”€â”€ model_loader.py          # Load base + LoRA model
â”‚   â”œâ”€â”€ prompts.py               # Prompt formatting
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ vector_store.py      # Qdrant memory interface
â”‚   â”‚   â”œâ”€â”€ web_search.py        # DuckDuckGo scraping
â”‚   â”‚   â””â”€â”€ answergpt-qlora/     # Fine-tuned LoRA model folder
â”œâ”€â”€ gradio_ui.py                # Web UI with Gradio
â”œâ”€â”€ data/
â”‚   â””â”€â”€ log.jsonl                # Chat logs for future training
â”œâ”€â”€ models/                     # [Optional] model artifacts
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Setup (Local)

### 1. Clone the Repo
```bash
git clone https://github.com/YOUR_USERNAME/answergpt.git
cd answergpt
```

### 2. (Optional) Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate  # On Windows
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```
> âœ… Or install manually:
```bash
pip install transformers peft qdrant-client sentence-transformers colorama gradio duckduckgo-search
```

### 4. Put Your Fine-Tuned Model in:
```
models/answergpt-qlora/
```
This should contain:
- `adapter_model.safetensors`
- `adapter_config.json`
- `tokenizer_config.json`, etc.

### 5. Run CLI Chatbot
```bash
python -m src.main
```

### 6. Run Gradio UI
```bash
python gradio_ui.py
```
It will launch in your browser at [http://127.0.0.1:7860](http://127.0.0.1:7860)

---

## âœ¨ Commands

- **remember ...** â€” Adds a fact to long-term vector memory (Qdrant)
```bash
You: remember Pluto is a dwarf planet
```
- **ask anything** â€” Hybrid context-aware answer
```bash
You: What is Pluto?
```

---

## ğŸ§  Training Your Own Model

You can fine-tune Phi-2 with QLoRA using the built-in training pipeline on Colab. Just run:
```python
src/modules/finetune_qlora.py
```
Make sure `data/log.jsonl` has high-quality Q&A logs.

---

## ğŸŒ Credits
- [Phi-2](https://huggingface.co/microsoft/phi-2) by Microsoft
- [QLoRA](https://arxiv.org/abs/2305.14314)
- [Gradio](https://gradio.app/)
- [Qdrant](https://qdrant.tech)

---

## ğŸ“„ License
This project is for educational & research purposes. You are responsible for compliance with licenses of pretrained models.

---

## ğŸ’¬ Contact
Feel free to reach out via GitHub Issues or contribute with a PR! Let's build the future of local AI together ğŸš€

